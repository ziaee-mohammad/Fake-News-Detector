{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1:\n",
    "***Evaluate the performance of your Simple and Advanced Models on your FakeNewsCorpus test set. It should be possible to achieve > 80% accuracy but you will not fail the project if your model cannot reach this performance.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Logistic regression for 995k + scraped:\n",
      "  - Loaded CSV.\n",
      "  - Ensured text data is string type.\n",
      "  - Vectorized text data.\n",
      "  - Used the binary 'label' column as the target variable.\n",
      "  - Splitting dataset into train, validation, and test sets.\n",
      "  - Implementing logistic regression.\n",
      "\n",
      "Results of logistic regression of 995k\n",
      "  - F1-score: 0.9197\n",
      "\n",
      "Hyperparameters for Logistic Regression:\n",
      "  - Max Iterations: 500\n",
      "  - Solver: saga\n",
      "  - Random State: 42\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "LOGISTIC REGRESSION FOR CLEANED_FILE.CSV \n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Beginning Logistic regression...\")\n",
    "\n",
    "# Load CSV\n",
    "data = pd.read_csv(\"WITHOUT_NUM_cleaned_file_with_labels.csv\")\n",
    "print(\"  - Loaded CSV.\")\n",
    "\n",
    "# Ensure text data is string type \n",
    "data[\"content\"] = data[\"content\"].fillna(\"\").astype(str)\n",
    "print(\"  - Ensured text data is string type.\")\n",
    "\n",
    "# Vectorize text data\n",
    "vectorizer = TfidfVectorizer(max_features=10000, binary=True)\n",
    "X = vectorizer.fit_transform(data[\"content\"])\n",
    "print(\"  - Vectorized text data.\")\n",
    "\n",
    "# Use the binary 'label' column as the target variable\n",
    "y = data[\"label\"].astype(int)  # Ensure 'label' is integer type\n",
    "print(\"  - Used the binary 'label' column as the target variable.\")\n",
    "\n",
    "# Splitting dataset into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print(\"  - Splitting dataset into train, validation, and test sets.\")\n",
    "\n",
    "# Implementing logistic regression\n",
    "clf = LogisticRegression(max_iter=500, random_state=42, solver=\"saga\", n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"  - Implementing logistic regression.\")\n",
    "\n",
    "# Evaluating the model\n",
    "y_pred = clf.predict(X_val)\n",
    "f1 = f1_score(y_val, y_pred, average=\"binary\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nResults of logistic regression of 995k\")\n",
    "print(f\"  - F1-score: {f1:.4f}\\n\")\n",
    "print(\"Hyperparameters for Logistic Regression:\")\n",
    "print(f\"  - Max Iterations: {clf.max_iter}\")\n",
    "print(f\"  - Solver: {clf.solver}\")\n",
    "print(f\"  - Random State: {clf.random_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have trained the model. Below we will not try to evaluate it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation on the FakeNewsCorpus test set:\n",
      "  - Test F1-score: 0.9180\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model on the test set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_test_pred, average=\"binary\")\n",
    "\n",
    "print(\"Final evaluation on the FakeNewsCorpus test set:\")\n",
    "print(f\"  - Test F1-score: {f1_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: \n",
    "\n",
    "***In order to allow you to play around cross-domain performance, try the same exercise on the LIAR dataset Links to an external site., where you know the labels, and can thus immediately calculate the performance. You are expected to directly evaluate the model you trained on the FakeNewsCorpus. In other words, you do not need to retrain the model on the LIAR dataset.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we need to make sure that the LIAR dataset has the same format as the original dataset. To do this we will therefor implement a similar cleaning approach as we did for Part 1. Note that we only clean the \"statement\" part of the LIAR dataset, which we acctually change to \"content\" to make it match our training data. Also, the LIAR dataset dosent have any headlines for the columns, so we also add those for convenience. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/simonhvidtfeldt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/simonhvidtfeldt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# The file we want to read:\n",
    "file_path = \"test.tsv\"\n",
    "chunksize = 40000 # Can in practice be ignored since this file is very small compared to the 995K. \n",
    "\n",
    "# Column names from README. The liar test doesnt have any headlines for columns, so we define those manually. \n",
    "column_names = [\n",
    "    \"id\", \"type\", \"content\", \"subjects\", \"speaker\", \"speaker_job_title\", \n",
    "    \"state_info\", \"party_affiliation\", \"barely_true\", \"false\", \"half_true\", \n",
    "    \"mostly_true\", \"pants_on_fire\", \"context\"\n",
    "]\n",
    "\n",
    "# We only want to clean statement (content). We can add the other columns if needed. \n",
    "columns_to_clean = [\"content\"]\n",
    "\n",
    "# Initialize NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Our clean_text function from Part 1:\n",
    "def clean_text(data):\n",
    "    if not isinstance(data, str):\n",
    "        return \"\"\n",
    "    data = data.lower()\n",
    "    data = re.sub(r'\\s+', \" \", data)\n",
    "    data = re.sub(r'\\d{1,2}[./-]\\d{1,2}[./-]\\d{2,4}', \"<DATE>\", data)\n",
    "    data = re.sub(r'(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec).? \\d{1,2},? \\d{4}', \"<DATE>\", data)\n",
    "    data = re.sub(r'\\d{4}-\\d{2}-\\d{2}', \"<DATE>\", data)\n",
    "    data = re.sub(r'[\\w._%+-]+@[\\w.-]+\\.[a-zA-Z]{2,}', \"<EMAIL>\", data)\n",
    "    data = re.sub(r'http[s]?://[^\\s]+', \"<URL>\", data)\n",
    "    data = re.sub(r'\\d+(\\.\\d+)?', \"<NUM>\", data)\n",
    "    return data\n",
    "\n",
    "# Our tokenize and stem function from Part 1:\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [ps.stem(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "#Process and store all chunks in a single DataFrame\n",
    "preprocessed_data = pd.DataFrame()\n",
    "\n",
    "for chunk in pd.read_csv(file_path, sep='\\t', chunksize=chunksize, \n",
    "                        low_memory=False, header=None, names=column_names):\n",
    "    \"\"\"SLIGTHLY EDITED FROM PART 1\"\"\"\n",
    "    # Process each specified column with your original 3-step pipeline\n",
    "    for col in columns_to_clean:\n",
    "        if col in chunk.columns:\n",
    "            # Step 1: Clean text (dates, URLs, etc.)\n",
    "            chunk[col] = chunk[col].apply(clean_text)\n",
    "            \n",
    "            # Step 2: Remove stopwords (your original lambda)\n",
    "            chunk[col] = chunk[col].astype(str).apply(\n",
    "                lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "            \n",
    "            # Step 3: Tokenize and stem\n",
    "            chunk[col] = chunk[col].apply(tokenize_and_stem)\n",
    "    \n",
    "    # Append processed chunk\n",
    "    preprocessed_data = pd.concat([preprocessed_data, chunk], ignore_index=True)\n",
    "\n",
    "# Save output now cleaned \n",
    "preprocessed_data.to_csv(\"LIAR_DATA_test_CLEANED.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. Now we are almost ready. We just need to make the labels binary in the LIAR dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Created the 'label' column\n",
      " - Converted 'True' to 1 and 'Fake' to 0\n",
      " - Dropped rows with NaN in the 'label' column\n",
      " - Saved the DataFrame to a CSV file\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "CODE FROM PART_2_TASK_1 *EDITED*\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "data_path = \"LIAR_DATA_test_CLEANED.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Define mapping\n",
    "label_mapping = {\n",
    "    \"true\": \"True\",\n",
    "    \"false\": \"Fake\",\n",
    "    \"half-true\": \"Fake\",\n",
    "    \"pants-fire\": \"Fake\",\n",
    "    \"barely-true\": \"Fake\",\n",
    "    \"mostly-true\": \"True\"\n",
    "}\n",
    "\n",
    "# Create the 'label' column\n",
    "data[\"label\"] = data[\"type\"].map(label_mapping)\n",
    "print(\" - Created the 'label' column\")\n",
    "\n",
    "# Convert 'True' to 1 and 'Fake' to 0\n",
    "data[\"label\"] = data[\"label\"].map({\"True\": 1, \"Fake\": 0})\n",
    "print(\" - Converted 'True' to 1 and 'Fake' to 0\")\n",
    "\n",
    "# Drop rows with NaN in the 'label' column (if any)\n",
    "data = data.dropna(subset=[\"label\"])\n",
    "print(\" - Dropped rows with NaN in the 'label' column\")\n",
    "\n",
    "# Save the DataFrame to a CSV file (if needed)\n",
    "data.to_csv(\"LIAR_DATA_test_CLEANED_label.csv\", index=False)\n",
    "print(\" - Saved the DataFrame to a CSV file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we are ready to evaluate the performance of our simple logistic regression on the LIAR dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your new dataset\n",
    "new_liar_data = pd.read_csv(\"LIAR_DATA_test_CLEANED_label.csv\")\n",
    "\n",
    "# Same process as orginal \n",
    "new_liar_data[\"content\"] = new_liar_data[\"content\"].fillna(\"\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the new text data using the existing vectorizer\n",
    "X_liar_data = vectorizer.transform(new_liar_data[\"content\"])\n",
    "\n",
    "# Get the labels\n",
    "y_liar_data = new_liar_data[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results of logistic regression on LIAR:\n",
      "  - F1-score: 0.5201\n",
      "\n",
      "Hyperparameters for Logistic Regression:\n",
      "  - Max Iterations: 500\n",
      "  - Solver: saga\n",
      "  - Random State: 42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Make predictions on the new data\n",
    "y_new_pred = clf.predict(X_liar_data)\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_liar_data, y_new_pred, average=\"binary\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nResults of logistic regression on LIAR:\")\n",
    "print(f\"  - F1-score: {f1:.4f}\\n\")\n",
    "print(\"Hyperparameters for Logistic Regression:\")\n",
    "print(f\"  - Max Iterations: {clf.max_iter}\")\n",
    "print(f\"  - Solver: {clf.solver}\")\n",
    "print(f\"  - Random State: {clf.random_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Comparison:\n",
      "  - FAKE News F1 : 0.9180\n",
      "  - New LIAR data F1: 0.5201\n"
     ]
    }
   ],
   "source": [
    "# Original validation performance\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(f\"  - FAKE News F1 : {f1_test:.4f}\")\n",
    "print(f\"  - New LIAR data F1: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
