# ðŸ§© Part 1 â€” Data Loading & Cleaning

This section focuses on preparing and cleaning the raw dataset before analysis.

## ðŸ§  Overview
We use the [FakeNewsCorpus](https://github.com/several27/FakeNewsCorpus/tree/master) dataset as the primary data source.  
The goal is to load, merge, and clean the dataset for later NLP and model training steps.

---

## âš™ Guidelines
- Ensure that the *99500K NewsCorpus* dataset is downloaded before running this script.  
- Make sure **no file named cleaned_file.csv** already exists in your working directory.

---

## ðŸš€ How to Run
Simply execute the Jupyter Notebook:

```bash
Part1_final.ipynb
